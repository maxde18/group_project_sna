---
title: "Electoral Cycle Network Analysis: Dutch Parliament 2023-2024"
subtitle: "Pre-Election vs. Post-Formation Party Cooperation Networks"
author: "Your Name"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    code_folding: show
    theme: flatly
    highlight: tango
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  results = 'asis',
  fig.width = 12,
  fig.height = 8,
  fig.path = "results/visualizations/"
)
print(paste("Working directory set to:", getwd()))
```

------------------------------------------------------------------------

# 1. Data Preparation

## 1.1 Load Data

```{r load-data}
# Load voting data
voting_data_2023 <- read.csv("data/voting_data_2023_preelection.csv", stringsAsFactors = FALSE)
voting_data_2024 <- read.csv("data/voting_data_clean.csv", stringsAsFactors = FALSE)

# Convert dates
voting_data_2023$date <- lubridate::ymd_hms(voting_data_2023$GewijzigdOp)
voting_data_2024$date <- lubridate::ymd_hms(voting_data_2024$GewijzigdOp)

# Load Kieskompas ideology data
ideology_data <- read.csv("data/political_axes_data.csv", stringsAsFactors = FALSE)
names(ideology_data) <- c("left_right", "conservative_progressive", "party")
ideology_data <- ideology_data[!is.na(ideology_data$party) & ideology_data$party != "", ]

print("Data loaded:")
print(sprintf("  • 2023 records: %s", format(nrow(voting_data_2023), big.mark = ",")))
print(sprintf("  • 2024 records: %s", format(nrow(voting_data_2024), big.mark = ",")))
print(sprintf("  • Ideology data: %d parties", nrow(ideology_data)))
```

## 1.2 General Preprocessing: Extract Motion Datasets

```{r general-preprocessing}
# Key dates
election_date <- lubridate::ymd("2023-11-22")
formation_date <- lubridate::ymd("2024-07-05")

# Extract motion dataset 1 year BEFORE election (Nov 22, 2022 - Nov 21, 2023)
pre_election_start <- election_date - lubridate::years(1)
pre_election_end <- election_date - lubridate::days(1)
motion_data_pre <- voting_data_2023[voting_data_2023$date >= pre_election_start & 
                                     voting_data_2023$date <= pre_election_end, ]

# Extract motion dataset 1 year AFTER formation (Jul 5, 2024 - Jul 4, 2025)
post_formation_start <- formation_date
post_formation_end <- formation_date + lubridate::years(1)
motion_data_post <- voting_data_2024[voting_data_2024$date >= post_formation_start & 
                                     voting_data_2024$date <= post_formation_end, ]

# Filter to valid parties (from ideology data)
valid_parties <- ideology_data$party
motion_data_pre <- motion_data_pre[motion_data_pre$ActorFractie %in% valid_parties, ]
motion_data_post <- motion_data_post[motion_data_post$ActorFractie %in% valid_parties, ]

print("GENERAL PREPROCESSING")
print("====================")
print(sprintf("Pre-election: %s votes, %s motions, %d parties", 
              format(nrow(motion_data_pre), big.mark = ","),
              format(length(unique(motion_data_pre$Besluit_Id)), big.mark = ","),
              length(unique(motion_data_pre$ActorFractie))))
print(sprintf("Post-formation: %s votes, %s motions, %d parties", 
              format(nrow(motion_data_post), big.mark = ","),
              format(length(unique(motion_data_post$Besluit_Id)), big.mark = ","),
              length(unique(motion_data_post$ActorFractie))))
```

## 1.3 Generate Edge Lists from Voting Data

```{r generate-edgelists}
# Function to generate edge list from motion dataset
generate_edgelist <- function(data) {
  party_votes <- data[, c("ActorFractie", "Besluit_Id", "Soort")]
  party_votes <- party_votes[!duplicated(party_votes), ]
  
  agreements_list <- list()
  unique_motions <- unique(party_votes$Besluit_Id)
  
  for(motion in unique_motions) {
    motion_data <- party_votes[party_votes$Besluit_Id == motion, ]
    parties_in_motion <- motion_data$ActorFractie
    votes_in_motion <- motion_data$Soort
    
    if(length(parties_in_motion) >= 2) {
      for(i in 1:(length(parties_in_motion)-1)) {
        for(j in (i+1):length(parties_in_motion)) {
          party1 <- parties_in_motion[i]
          party2 <- parties_in_motion[j]
          vote1 <- votes_in_motion[i]
          vote2 <- votes_in_motion[j]
          
          if(party1 < party2) {
            pair_id <- paste(party1, party2, sep = "_")
            agreement <- ifelse(vote1 == vote2, 1, 0)
          } else {
            pair_id <- paste(party2, party1, sep = "_")
            agreement <- ifelse(vote1 == vote2, 1, 0)
          }
          
          if(pair_id %in% names(agreements_list)) {
            agreements_list[[pair_id]]$total_votes <- agreements_list[[pair_id]]$total_votes + 1
            agreements_list[[pair_id]]$agreements <- agreements_list[[pair_id]]$agreements + agreement
          } else {
            agreements_list[[pair_id]] <- list(
              party1 = ifelse(party1 < party2, party1, party2),
              party2 = ifelse(party1 < party2, party2, party1),
              total_votes = 1,
              agreements = agreement
            )
          }
        }
      }
    }
  }
  
  if(length(agreements_list) > 0) {
    edgelist <- data.frame(
      from = sapply(agreements_list, function(x) x$party1),
      to = sapply(agreements_list, function(x) x$party2),
      weight = sapply(agreements_list, function(x) x$agreements),
      stringsAsFactors = FALSE
    )
  } else {
    edgelist <- data.frame(
      from = character(0),
      to = character(0),
      weight = numeric(0),
      stringsAsFactors = FALSE
    )
  }
  
  return(edgelist)
}

# Generate edge lists for both periods
edgelist_pre <- generate_edgelist(motion_data_pre)
edgelist_post <- generate_edgelist(motion_data_post)

print("EDGE LISTS GENERATED")
print("====================")
print(sprintf("Pre-election edges: %d", nrow(edgelist_pre)))
print(sprintf("Post-formation edges: %d", nrow(edgelist_post)))
```

## 1.4 Z-Score Normalization

```{r normalize-edgelists}
# Function to normalize edge weights (z-score)
normalize_edgelist <- function(edgelist) {
  if(nrow(edgelist) == 0) return(edgelist)
  mean_weight <- mean(edgelist$weight)
  sd_weight <- sd(edgelist$weight)
  edgelist$weight_normalized <- (edgelist$weight - mean_weight) / sd_weight
  return(edgelist)
}

# Normalize edge lists
edgelist_pre_norm <- normalize_edgelist(edgelist_pre)
edgelist_post_norm <- normalize_edgelist(edgelist_post)

print("EDGE LISTS NORMALIZED (Z-SCORE)")
print("===============================")
print("Normalized edge lists ready for analysis")
```

## 1.5 Create Fully Connected Networks

Both Study 1 (QAP) and Study 2 (GERGM) require fully connected networks. We create these networks with all parties from the ideology data, setting zero edge weights to 1e-6 for full connectivity.

```{r fully-connected-networks}
# Use all parties from ideology data for both studies
all_parties <- sort(ideology_data$party)

# Create networks with normalized weights
g_pre_norm <- create_graph(edgelist_pre_norm, all_parties, use_normalized = TRUE)
g_post_norm <- create_graph(edgelist_post_norm, all_parties, use_normalized = TRUE)

# Generate adjacency matrices
adj_matrix_pre <- igraph::as_adjacency_matrix(g_pre_norm, attr = "weight", sparse = FALSE)
adj_matrix_post <- igraph::as_adjacency_matrix(g_post_norm, attr = "weight", sparse = FALSE)

# Set 0 values to 1e-6 to make fully connected (but keep diagonal as 0)
adj_matrix_pre[adj_matrix_pre == 0] <- 1e-6
adj_matrix_post[adj_matrix_post == 0] <- 1e-6
diag(adj_matrix_pre) <- 0
diag(adj_matrix_post) <- 0

# Regenerate fully connected networks
g_pre_connected <- igraph::graph_from_adjacency_matrix(adj_matrix_pre, 
                                                       mode = "undirected", 
                                                       weighted = TRUE)
g_post_connected <- igraph::graph_from_adjacency_matrix(adj_matrix_post, 
                                                        mode = "undirected", 
                                                        weighted = TRUE)

# Set vertex names
igraph::V(g_pre_connected)$name <- all_parties
igraph::V(g_post_connected)$name <- all_parties

print("FULLY CONNECTED NETWORKS CREATED")
print("=================================")
print(sprintf("Pre-election: %d nodes, fully connected (%d edges)", 
              snafun::count_vertices(g_pre_connected), snafun::count_edges(g_pre_connected)))
print(sprintf("Post-formation: %d nodes, fully connected (%d edges)", 
              snafun::count_vertices(g_post_connected), snafun::count_edges(g_post_connected)))
print("All zero edge weights set to 1e-6 for full connectivity")
print("Networks ready for both Study 1 (QAP) and Study 2 (GERGM)")

# Export adjacency matrices
if(!dir.exists("results/adjacency_matrices")) {
  dir.create("results/adjacency_matrices", recursive = TRUE)
}
write.csv(adj_matrix_pre, "results/adjacency_matrices/pre_election_adjacency.csv", 
          row.names = TRUE)
write.csv(adj_matrix_post, "results/adjacency_matrices/post_formation_adjacency.csv", 
          row.names = TRUE)
print("Adjacency matrices exported")
```

------------------------------------------------------------------------

# 2. Data Exploration

## 2.1 Ideology Correlation

```{r ideology-correlation}
# Pearson correlation between ideology dimensions
pearson_test <- stats::cor.test(ideology_data$left_right, 
                         ideology_data$conservative_progressive, 
                         method = "pearson")

print("IDEOLOGY CORRELATION")
print("====================")
print(sprintf("Pearson r = %.3f (p = %.4f)", pearson_test$estimate, pearson_test$p.value))

# Scatterplot
plot(ideology_data$left_right, ideology_data$conservative_progressive,
     xlab = "Left-Right", ylab = "Conservative-Progressive",
     main = sprintf("Ideology Dimensions (r = %.3f)", pearson_test$estimate),
     pch = 19, col = "steelblue")
abline(lm(conservative_progressive ~ left_right, data = ideology_data), 
       col = "red", lwd = 2)
text(ideology_data$left_right, ideology_data$conservative_progressive, 
     labels = ideology_data$party, pos = 3, cex = 0.7)
```

## 2.2 Vote Unanimity

```{r vote-unanimity}
# Calculate agreement rates per motion
calculate_agreement_rate <- function(data) {
  unique_votes <- data[, c("Besluit_Id", "ActorFractie", "Soort")]
  unique_votes <- unique_votes[!duplicated(unique_votes), ]
  unique_motions <- unique(unique_votes$Besluit_Id)
  
  agreement_rates <- sapply(unique_motions, function(motion_id) {
    motion_votes <- unique_votes[unique_votes$Besluit_Id == motion_id, ]
    voor <- sum(motion_votes$Soort == "Voor")
    tegen <- sum(motion_votes$Soort == "Tegen")
    total <- nrow(motion_votes)
    pmax(voor, tegen) / total
  })
  return(agreement_rates)
}

# Calculate for both periods
agreement_pre <- calculate_agreement_rate(motion_data_pre)
agreement_post <- calculate_agreement_rate(motion_data_post)

print("VOTE UNANIMITY")
print("==============")
print(sprintf("Pre-election: Mean agreement = %.3f", mean(agreement_pre)))
print(sprintf("Post-formation: Mean agreement = %.3f", mean(agreement_post)))

# Comparison boxplot
boxplot(list(Pre = agreement_pre, Post = agreement_post),
        main = "Agreement Rate Comparison",
        ylab = "Agreement Rate", col = c("#E74C3C", "#3498DB"))
```

## 2.3 Network Visualizations

```{r network-visualizations}
# Function to create graph from edgelist
create_graph <- function(edgelist, vertices, use_normalized = FALSE) {
  if(nrow(edgelist) > 0) {
    edgelist_filtered <- edgelist[edgelist$from %in% vertices & 
                                   edgelist$to %in% vertices, ]
    
    if(nrow(edgelist_filtered) > 0) {
      if(use_normalized && "weight_normalized" %in% names(edgelist_filtered)) {
        g <- igraph::graph_from_data_frame(edgelist_filtered[, c("from", "to", "weight_normalized")], 
                                           directed = FALSE, vertices = vertices)
        igraph::E(g)$weight <- edgelist_filtered$weight_normalized
      } else {
        g <- igraph::graph_from_data_frame(edgelist_filtered[, c("from", "to", "weight")], 
                                           directed = FALSE, vertices = vertices)
        igraph::E(g)$weight <- edgelist_filtered$weight
      }
    } else {
      g <- igraph::graph_from_data_frame(data.frame(), directed = FALSE, vertices = vertices)
    }
  } else {
    g <- igraph::graph_from_data_frame(data.frame(), directed = FALSE, vertices = vertices)
  }
  return(g)
}

# Create raw networks for visualization
all_parties <- sort(ideology_data$party)
g_pre_raw <- create_graph(edgelist_pre, all_parties, use_normalized = FALSE)
g_post_raw <- create_graph(edgelist_post, all_parties, use_normalized = FALSE)

# Create normalized networks
g_pre_norm <- create_graph(edgelist_pre_norm, all_parties, use_normalized = TRUE)
g_post_norm <- create_graph(edgelist_post_norm, all_parties, use_normalized = TRUE)

print("NETWORKS CREATED")
print("===============")
print(sprintf("Pre-election (raw): %d nodes, %d edges", 
              snafun::count_vertices(g_pre_raw), snafun::count_edges(g_pre_raw)))
print(sprintf("Post-formation (raw): %d nodes, %d edges", 
              snafun::count_vertices(g_post_raw), snafun::count_edges(g_post_raw)))
print(sprintf("Pre-election (normalized): %d nodes, %d edges", 
              snafun::count_vertices(g_pre_norm), snafun::count_edges(g_pre_norm)))
print(sprintf("Post-formation (normalized): %d nodes, %d edges", 
              snafun::count_vertices(g_post_norm), snafun::count_edges(g_post_norm)))

# Add ideology attributes for visualization (matching reference script)
add_ideology_for_visualization <- function(g, ideology_data) {
  party_names <- igraph::V(g)$name
  
  # Add left_right and conservative_progressive
  left_right_vals <- sapply(party_names, function(p) {
    idx <- which(ideology_data$party == p)
    if(length(idx) > 0) ideology_data$left_right[idx[1]] else NA
  })
  igraph::V(g)$left_right <- left_right_vals
  
  conservative_progressive_vals <- sapply(party_names, function(p) {
    idx <- which(ideology_data$party == p)
    if(length(idx) > 0) ideology_data$conservative_progressive[idx[1]] else NA
  })
  igraph::V(g)$conservative_progressive <- conservative_progressive_vals
  
  # Party categories for coloring (matching reference script)
  # Left: negative values (< -0.2)
  # Center: close to 0 (-0.2 to 0.2)
  # Right: positive values (> 0.2)
  party_type <- ifelse(
    party_names %in% c("BIJ1", "PvdD", "GroenLinks", "PvdA", "GroenLinks-PvdA", "DENK", "SP", "ChristenUnie", "50PLUS"), "Left",
    ifelse(party_names %in% c("Volt", "D66", "NSC", "BBB"), "Center", "Right")
  )
  igraph::V(g)$party_type <- party_type
  
  # Ideology for layout (matching reference script)
  ideology_pos <- ifelse(
    party_names %in% c("BIJ1", "PvdD", "GroenLinks", "PvdA", "GroenLinks-PvdA", "DENK", "SP"), 1,
    ifelse(party_names %in% c("ChristenUnie", "50PLUS", "Volt", "D66", "NSC", "Omtzigt"), 2,
    ifelse(party_names %in% c("BBB", "PVV", "CDA"), 3,
    ifelse(party_names %in% c("VVD", "SGP"), 4, 5)))
  )
  igraph::V(g)$ideology <- ideology_pos
  
  return(g)
}

# Add ideology attributes to all networks for visualization
g_pre_raw <- add_ideology_for_visualization(g_pre_raw, ideology_data)
g_post_raw <- add_ideology_for_visualization(g_post_raw, ideology_data)
g_pre_norm <- add_ideology_for_visualization(g_pre_norm, ideology_data)
g_post_norm <- add_ideology_for_visualization(g_post_norm, ideology_data)

# Create ideology-based layout (matching reference script exactly)
party_colors <- c("Left" = "#E74C3C", "Center" = "#F39C12", "Right" = "#3498DB")

set.seed(42)  # Same seed as reference for reproducibility
layout_coords <- matrix(0, nrow = length(all_parties), ncol = 2)
for(i in seq_along(all_parties)) {
  party <- all_parties[i]
  if(party %in% igraph::V(g_pre_norm)$name) {
    ideology_pos <- igraph::V(g_pre_norm)$ideology[igraph::V(g_pre_norm)$name == party][1]
  } else if(party %in% igraph::V(g_post_norm)$name) {
    ideology_pos <- igraph::V(g_post_norm)$ideology[igraph::V(g_post_norm)$name == party][1]
  } else {
    ideology_pos <- 3
  }
  layout_coords[i, 1] <- ideology_pos + stats::runif(1, -0.3, 0.3)
  layout_coords[i, 2] <- stats::runif(1, -1, 1)
}

# Visualization function matching reference script
visualize_network_normalized <- function(g, title, layout_coords, all_parties) {
  # Color and size nodes (matching reference)
  igraph::V(g)$color <- party_colors[igraph::V(g)$party_type]
  igraph::V(g)$size <- pmax(8, sqrt(igraph::degree(g)) * 4)
  
  # Edge styling for normalized networks (z-score)
  if(snafun::count_edges(g) > 0) {
    # Scale z-scores for visibility (matching reference)
    igraph::E(g)$width <- pmax(0.3, (igraph::E(g)$weight + 3) / 6 * 3)
    # Highlight edges with z > 1.0 (above average)
    igraph::E(g)$color <- ifelse(igraph::E(g)$weight > 1.0, 
                                 grDevices::rgb(0.3, 0.3, 0.3, 0.8),   # Strong: z > 1
                                 grDevices::rgb(0.5, 0.5, 0.5, 0.15))  # Weak: z <= 1
  }
  
  # Match layout to party order
  layout_match <- layout_coords[match(igraph::V(g)$name, all_parties), ]
  
  plot(g, layout = layout_match,
       vertex.label.cex = 0.7,
       vertex.label.color = "black",
       vertex.label.family = "sans",
       vertex.frame.color = "white",
       main = title)
}

visualize_network_raw <- function(g, title, layout_coords, all_parties) {
  # Color and size nodes (matching reference)
  igraph::V(g)$color <- party_colors[igraph::V(g)$party_type]
  igraph::V(g)$size <- pmax(8, sqrt(igraph::degree(g)) * 4)
  
  # Edge styling for raw networks
  if(snafun::count_edges(g) > 0) {
    # Use raw weights for visualization
    igraph::E(g)$width <- pmax(0.5, (igraph::E(g)$weight / max(igraph::E(g)$weight)) * 3)
    mean_raw <- mean(igraph::E(g)$weight)
    threshold <- mean_raw * 1.3
    igraph::E(g)$color <- ifelse(igraph::E(g)$weight >= threshold,
                                 grDevices::rgb(0.3, 0.3, 0.3, 0.8),
                                 grDevices::rgb(0.5, 0.5, 0.5, 0.15))
  }
  
  # Match layout to party order
  layout_match <- layout_coords[match(igraph::V(g)$name, all_parties), ]
  
  plot(g, layout = layout_match,
       vertex.label.cex = 0.7,
       vertex.label.color = "black",
       vertex.frame.color = "white",
       main = title)
}

# Visualize raw networks
par(mfrow = c(1, 2), mar = c(2, 2, 4, 2))
visualize_network_raw(g_pre_raw, "PRE-ELECTION (RAW WEIGHTS)\n(Nov 22, 2022 - Nov 21, 2023)", 
                      layout_coords, all_parties)
visualize_network_raw(g_post_raw, "POST-FORMATION (RAW WEIGHTS)\n(Jul 5, 2024 - Jul 4, 2025)", 
                      layout_coords, all_parties)

# Visualize normalized networks
par(mfrow = c(1, 2), mar = c(2, 2, 4, 2))
visualize_network_normalized(g_pre_norm, "PRE-ELECTION (Z-SCORE NORMALIZED)\n(Nov 22, 2022 - Nov 21, 2023)", 
                             layout_coords, all_parties)
visualize_network_normalized(g_post_norm, "POST-FORMATION (Z-SCORE NORMALIZED)\n(Jul 5, 2024 - Jul 4, 2025)", 
                             layout_coords, all_parties)
```

## 2.4 Z-Score Normalization Motivation

```{r zscore-motivation}
# Calculate statistics to motivate z-score normalization
calculate_zscore_stats <- function(edgelist_norm, period_name) {
  if(nrow(edgelist_norm) == 0 || !"weight_normalized" %in% names(edgelist_norm)) {
    return(list(total_edges = 0, strong_ties = 0, pct_strong = "0.0%", very_strong = 0))
  }
  
  total_edges <- nrow(edgelist_norm)
  strong_ties <- sum(edgelist_norm$weight_normalized > 1.0, na.rm = TRUE)
  pct_strong <- round(100 * strong_ties / total_edges, 1)
  very_strong <- sum(edgelist_norm$weight_normalized > 2.0, na.rm = TRUE)
  
  return(list(
    total_edges = total_edges,
    strong_ties = strong_ties,
    pct_strong = paste0(pct_strong, "%"),
    very_strong = very_strong
  ))
}

stats_pre_zscore <- calculate_zscore_stats(edgelist_pre_norm, "Pre-Election")
stats_post_zscore <- calculate_zscore_stats(edgelist_post_norm, "Post-Formation")

zscore_stats_table <- data.frame(
  Metric = c("Total Edges", "Strong Ties (z>1)", "% Strong Ties", "Very Strong (z>2)"),
  Pre_Election = c(
    as.character(stats_pre_zscore$total_edges),
    as.character(stats_pre_zscore$strong_ties),
    stats_pre_zscore$pct_strong,
    as.character(stats_pre_zscore$very_strong)
  ),
  Post_Formation = c(
    as.character(stats_post_zscore$total_edges),
    as.character(stats_post_zscore$strong_ties),
    stats_post_zscore$pct_strong,
    as.character(stats_post_zscore$very_strong)
  ),
  stringsAsFactors = FALSE
)

print("Z-SCORE NORMALIZATION STATISTICS")
print("=================================")
print(knitr::kable(zscore_stats_table, align = 'lrr'))

# Compare raw weights
print("")
print("RAW WEIGHT COMPARISON:")
print(sprintf("Pre-election: Mean = %.1f, SD = %.1f, Range = [%.0f, %.0f]",
              mean(edgelist_pre$weight), sd(edgelist_pre$weight),
              min(edgelist_pre$weight), max(edgelist_pre$weight)))
print(sprintf("Post-formation: Mean = %.1f, SD = %.1f, Range = [%.0f, %.0f]",
              mean(edgelist_post$weight), sd(edgelist_post$weight),
              min(edgelist_post$weight), max(edgelist_post$weight)))
print("")
print("Z-score normalization enables cross-period comparison by standardizing edge weights.")
```

## 2.5 Co-Sponsorship Exploration

```{r cosponsorship-exploration}
# Load co-sponsorship data
library(jsonlite)

coauth_pre_file <- "data/coauthoring_data_2023_preelection.json"
coauth_post_file <- "data/coauthoring_data_2024_postformation.json"

if(file.exists(coauth_pre_file) && file.exists(coauth_post_file)) {
  coauth_pre_items <- fromJSON(coauth_pre_file)
  coauth_post_items <- fromJSON(coauth_post_file)
  
  # Build document-actor table
  build_document_actor_table <- function(items) {
    if(length(items) == 0 || (is.data.frame(items) && nrow(items) == 0)) {
      return(data.frame(document_id = character(0), relatie = character(0), 
                        actor_fractie = character(0), stringsAsFactors = FALSE))
    }
    
    doc_actor_list <- list()
    
    if(is.data.frame(items)) {
      for(i in seq_len(nrow(items))) {
        doc_id <- items$Id[i]
        doc_actors <- items$DocumentActor[[i]]
        
        if(!is.null(doc_actors) && length(doc_actors) > 0 && is.data.frame(doc_actors)) {
          for(j in seq_len(nrow(doc_actors))) {
            relatie <- doc_actors$Relatie[j]
            actor_fractie <- doc_actors$ActorFractie[j]
            
            if(!is.null(relatie) && !is.null(actor_fractie) && !is.na(actor_fractie)) {
              doc_actor_list[[length(doc_actor_list) + 1]] <- data.frame(
                document_id = doc_id, relatie = relatie, actor_fractie = actor_fractie,
                stringsAsFactors = FALSE)
            }
          }
        }
      }
    }
    
    if(length(doc_actor_list) > 0) {
      return(do.call(rbind, doc_actor_list))
    } else {
      return(data.frame(document_id = character(0), relatie = character(0), 
                        actor_fractie = character(0), stringsAsFactors = FALSE))
    }
  }
  
  doc_actor_pre <- build_document_actor_table(coauth_pre_items)
  doc_actor_post <- build_document_actor_table(coauth_post_items)
  
  # Calculate co-sponsorship counts (undirected)
  cosign_counts <- function(doc_actor) {
    if(nrow(doc_actor) == 0) {
      return(data.frame(from = character(0), to = character(0), weight = numeric(0),
                        stringsAsFactors = FALSE))
    }
    
    doc_actor$relatie <- trimws(tolower(doc_actor$relatie))
    sponsors <- doc_actor[doc_actor$relatie == "eerste ondertekenaar", 
                          c("document_id", "actor_fractie")]
    sponsors <- unique(sponsors)
    names(sponsors)[names(sponsors) == "actor_fractie"] <- "sponsor"
    
    cosigners <- doc_actor[doc_actor$relatie == "mede ondertekenaar", 
                           c("document_id", "actor_fractie")]
    cosigners <- unique(cosigners)
    names(cosigners)[names(cosigners) == "actor_fractie"] <- "cosigner"
    
    pairs <- merge(cosigners, sponsors, by = "document_id", all = FALSE)
    pairs <- pairs[pairs$cosigner != pairs$sponsor & 
                   !is.na(pairs$cosigner) & !is.na(pairs$sponsor), ]
    
    if(nrow(pairs) > 0) {
      pairs$party_lo <- pmin(pairs$cosigner, pairs$sponsor)
      pairs$party_hi <- pmax(pairs$cosigner, pairs$sponsor)
      undirected <- aggregate(rep(1, nrow(pairs)), 
                            by = list(from = pairs$party_lo, to = pairs$party_hi), 
                            FUN = sum)
      names(undirected)[names(undirected) == "x"] <- "weight"
      return(undirected)
    } else {
      return(data.frame(from = character(0), to = character(0), weight = numeric(0),
                        stringsAsFactors = FALSE))
    }
  }
  
  edgelist_cosponsor_pre <- cosign_counts(doc_actor_pre)
  edgelist_cosponsor_post <- cosign_counts(doc_actor_post)
  
  print("CO-SPONSORSHIP EXPLORATION")
  print("===========================")
  print("")
  
  # Pre-election analysis
  print("PRE-ELECTION:")
  print(sprintf("  Total co-sponsorship pairs: %d", nrow(edgelist_cosponsor_pre)))
  if(nrow(edgelist_cosponsor_pre) > 0) {
    print(sprintf("  Mean co-sponsorships per pair: %.1f", mean(edgelist_cosponsor_pre$weight)))
    print(sprintf("  Max co-sponsorships: %.0f", max(edgelist_cosponsor_pre$weight)))
    
    # Top co-sponsorship pairs
    edgelist_cosponsor_pre_sorted <- edgelist_cosponsor_pre[order(-edgelist_cosponsor_pre$weight), ]
    print("")
    print("  Top 10 co-sponsorship pairs:")
    for(i in seq_len(min(10, nrow(edgelist_cosponsor_pre_sorted)))) {
      print(sprintf("    %2d. %s - %s: %d co-sponsorships", 
                    i, edgelist_cosponsor_pre_sorted$from[i], 
                    edgelist_cosponsor_pre_sorted$to[i], 
                    edgelist_cosponsor_pre_sorted$weight[i]))
    }
    
    # Parties with most co-sponsorships
    all_parties_cosponsor_pre <- unique(c(edgelist_cosponsor_pre$from, edgelist_cosponsor_pre$to))
    party_counts_pre <- sapply(all_parties_cosponsor_pre, function(p) {
      sum(edgelist_cosponsor_pre$weight[edgelist_cosponsor_pre$from == p | 
                                        edgelist_cosponsor_pre$to == p])
    })
    party_counts_pre_sorted <- sort(party_counts_pre, decreasing = TRUE)
    print("")
    print("  Parties with most co-sponsorships:")
    for(i in seq_len(min(10, length(party_counts_pre_sorted)))) {
      print(sprintf("    %2d. %s: %d total co-sponsorships", 
                    i, names(party_counts_pre_sorted)[i], party_counts_pre_sorted[i]))
    }
  }
  
  print("")
  print("POST-FORMATION:")
  print(sprintf("  Total co-sponsorship pairs: %d", nrow(edgelist_cosponsor_post)))
  if(nrow(edgelist_cosponsor_post) > 0) {
    print(sprintf("  Mean co-sponsorships per pair: %.1f", mean(edgelist_cosponsor_post$weight)))
    print(sprintf("  Max co-sponsorships: %.0f", max(edgelist_cosponsor_post$weight)))
    
    # Top co-sponsorship pairs
    edgelist_cosponsor_post_sorted <- edgelist_cosponsor_post[order(-edgelist_cosponsor_post$weight), ]
    print("")
    print("  Top 10 co-sponsorship pairs:")
    for(i in seq_len(min(10, nrow(edgelist_cosponsor_post_sorted)))) {
      print(sprintf("    %2d. %s - %s: %d co-sponsorships", 
                    i, edgelist_cosponsor_post_sorted$from[i], 
                    edgelist_cosponsor_post_sorted$to[i], 
                    edgelist_cosponsor_post_sorted$weight[i]))
    }
    
    # Parties with most co-sponsorships
    all_parties_cosponsor_post <- unique(c(edgelist_cosponsor_post$from, edgelist_cosponsor_post$to))
    party_counts_post <- sapply(all_parties_cosponsor_post, function(p) {
      sum(edgelist_cosponsor_post$weight[edgelist_cosponsor_post$from == p | 
                                         edgelist_cosponsor_post$to == p])
    })
    party_counts_post_sorted <- sort(party_counts_post, decreasing = TRUE)
    print("")
    print("  Parties with most co-sponsorships:")
    for(i in seq_len(min(10, length(party_counts_post_sorted)))) {
      print(sprintf("    %2d. %s: %d total co-sponsorships", 
                    i, names(party_counts_post_sorted)[i], party_counts_post_sorted[i]))
    }
  }
  
  # Comparison between periods
  print("")
  print("COMPARISON:")
  if(nrow(edgelist_cosponsor_pre) > 0 && nrow(edgelist_cosponsor_post) > 0) {
    # Find pairs that appear in both periods
    pairs_pre <- paste(edgelist_cosponsor_pre$from, edgelist_cosponsor_pre$to, sep = "_")
    pairs_post <- paste(edgelist_cosponsor_post$from, edgelist_cosponsor_post$to, sep = "_")
    common_pairs <- intersect(pairs_pre, pairs_post)
    
    print(sprintf("  Common pairs in both periods: %d", length(common_pairs)))
    if(length(common_pairs) > 0) {
      print("  Pairs with increased co-sponsorships (post > pre):")
      increased_count <- 0
      for(pair in common_pairs) {
        parts <- strsplit(pair, "_")[[1]]
        weight_pre <- edgelist_cosponsor_pre$weight[edgelist_cosponsor_pre$from == parts[1] & 
                                                     edgelist_cosponsor_pre$to == parts[2]]
        weight_post <- edgelist_cosponsor_post$weight[edgelist_cosponsor_post$from == parts[1] & 
                                                       edgelist_cosponsor_post$to == parts[2]]
        if(length(weight_pre) > 0 && length(weight_post) > 0 && weight_post > weight_pre) {
          increased_count <- increased_count + 1
          if(increased_count <= 5) {
            print(sprintf("    %s - %s: %d → %d (+%d)", 
                          parts[1], parts[2], weight_pre, weight_post, weight_post - weight_pre))
          }
        }
      }
    }
  }
} else {
  print("WARNING: Co-sponsorship JSON files not found.")
  edgelist_cosponsor_pre <- data.frame(from = character(0), to = character(0), 
                                        weight = numeric(0), stringsAsFactors = FALSE)
  edgelist_cosponsor_post <- data.frame(from = character(0), to = character(0), 
                                         weight = numeric(0), stringsAsFactors = FALSE)
}
```

## 2.6 Coalition Exploration

```{r coalition-exploration}
# Load coalition data
coalition_edgelist <- read.csv("data/nrtimes_coalition_together.csv", stringsAsFactors = FALSE)

# Handle potential parsing issues
if(ncol(coalition_edgelist) == 1) {
  col_name <- names(coalition_edgelist)[1]
  if(grepl("Source", col_name, ignore.case = TRUE) && 
     grepl("Target", col_name, ignore.case = TRUE) && 
     grepl("Weight", col_name, ignore.case = TRUE)) {
    first_row <- coalition_edgelist[1, 1]
    if(grepl("Source", first_row, ignore.case = TRUE)) {
      data_rows <- coalition_edgelist[-1, 1]
    } else {
      data_rows <- coalition_edgelist[, 1]
    }
    split_rows <- strsplit(data_rows, ",")
    coalition_edgelist <- data.frame(
      Source = trimws(sapply(split_rows, function(x) x[1])),
      Target = trimws(sapply(split_rows, function(x) x[2])),
      Weight = as.numeric(trimws(sapply(split_rows, function(x) x[3]))),
      stringsAsFactors = FALSE
    )
  }
}

# Standardize column names
if("Source" %in% names(coalition_edgelist)) {
  names(coalition_edgelist)[names(coalition_edgelist) == "Source"] <- "from"
}
if("Target" %in% names(coalition_edgelist)) {
  names(coalition_edgelist)[names(coalition_edgelist) == "Target"] <- "to"
}
if("Weight" %in% names(coalition_edgelist)) {
  names(coalition_edgelist)[names(coalition_edgelist) == "Weight"] <- "weight"
}

# Filter to parties in motion datasets
parties_in_motions <- sort(unique(c(unique(motion_data_pre$ActorFractie), 
                                    unique(motion_data_post$ActorFractie))))
parties_in_motions <- parties_in_motions[!is.na(parties_in_motions)]

coalition_edgelist_filtered <- coalition_edgelist[
  coalition_edgelist$from %in% parties_in_motions & 
  coalition_edgelist$to %in% parties_in_motions, 
]

print("COALITION EXPLORATION")
print("=====================")
print(sprintf("Total coalition edges: %d", nrow(coalition_edgelist_filtered)))
if(nrow(coalition_edgelist_filtered) > 0) {
  print(sprintf("Mean coalition count: %.1f", mean(coalition_edgelist_filtered$weight)))
  print(sprintf("Max coalition count: %.0f", max(coalition_edgelist_filtered$weight)))
  
  # Top coalition pairs
  coalition_sorted <- coalition_edgelist_filtered[order(-coalition_edgelist_filtered$weight), ]
  print("")
  print("Top 5 coalition pairs:")
  for(i in seq_len(min(5, nrow(coalition_sorted)))) {
    print(sprintf("  %d. %s - %s: %d times", i, coalition_sorted$from[i], 
                  coalition_sorted$to[i], coalition_sorted$weight[i]))
  }
}
```

------------------------------------------------------------------------

# 3. Study 1 Preprocessing (QAP)

## 3.1 Use Fully Connected Networks

Study 1 compares network structures between pre-election and post-formation periods using QAP (Quadratic Assignment Procedure). We use the fully connected networks created in general preprocessing.

```{r study1-networks}
# Study 1 uses the fully connected networks from general preprocessing
g_study1_pre_connected <- g_pre_connected
g_study1_post_connected <- g_post_connected

print("STUDY 1: USING FULLY CONNECTED NETWORKS")
print("========================================")
print(sprintf("Pre-election: %d nodes, fully connected", 
              snafun::count_vertices(g_study1_pre_connected)))
print(sprintf("Post-formation: %d nodes, fully connected", 
              snafun::count_vertices(g_study1_post_connected)))
print("Networks ready for QAP analysis")
```

------------------------------------------------------------------------

# 4. Study 2 Preprocessing (GERGM)

## 4.1 Add Ideology Attributes to Fully Connected Networks

Study 2 uses GERGM (Generalized Exponential Random Graph Model) to model network formation with covariates. We start with the fully connected networks from general preprocessing and add ideology attributes to vertices.

```{r study2-networks}
# Study 2 uses the fully connected networks from general preprocessing
# Add ideology attributes to vertices
add_ideology_attributes <- function(g, ideology_data) {
  party_names <- igraph::V(g)$name
  left_right_vals <- sapply(party_names, function(p) {
    idx <- which(ideology_data$party == p)
    if(length(idx) > 0) ideology_data$left_right[idx[1]] else NA
  })
  igraph::V(g)$left_right <- left_right_vals
  return(g)
}

g_study2_pre <- add_ideology_attributes(g_pre_connected, ideology_data)
g_study2_post <- add_ideology_attributes(g_post_connected, ideology_data)

print("STUDY 2: IDEOLOGY ATTRIBUTES ADDED")
print("===================================")
print(sprintf("Pre-election: %d nodes, fully connected (%d edges)", 
              snafun::count_vertices(g_study2_pre), snafun::count_edges(g_study2_pre)))
print(sprintf("Post-formation: %d nodes, fully connected (%d edges)", 
              snafun::count_vertices(g_study2_post), snafun::count_edges(g_study2_post)))
print("Left-right ideology attributes added to vertices")
```

## 4.2 Add Co-Sponsorship and Coalition Edge Attributes

```{r study2-edge-attributes}
# Function to add edge attribute from edgelist
add_edge_attribute <- function(g_voting, edgelist_attribute, attr_name) {
  edges_voting <- igraph::as_data_frame(g_voting, what = "edges")
  
  # Create canonical party pair names (alphabetical order) for matching
  edges_voting$party_pair <- paste(
    pmin(edges_voting$from, edges_voting$to),
    pmax(edges_voting$from, edges_voting$to),
    sep = "_"
  )
  
  # Create canonical party pair names for attribute edges
  if(nrow(edgelist_attribute) > 0) {
    edgelist_attribute$party_pair <- paste(
      pmin(edgelist_attribute$from, edgelist_attribute$to),
      pmax(edgelist_attribute$from, edgelist_attribute$to),
      sep = "_"
    )
    
    # Match attribute weights to voting edges
    attr_lookup <- edgelist_attribute$weight
    names(attr_lookup) <- edgelist_attribute$party_pair
    
    # Add attribute (0 if no relationship)
    edges_voting[[attr_name]] <- ifelse(
      edges_voting$party_pair %in% names(attr_lookup),
      attr_lookup[edges_voting$party_pair],
      0
    )
  } else {
    edges_voting[[attr_name]] <- 0
  }
  
  # Remove temporary party_pair column
  edges_voting$party_pair <- NULL
  
  # Recreate graph with attribute
  g_with_attr <- igraph::graph_from_data_frame(edges_voting, directed = FALSE,
                                                vertices = igraph::V(g_voting)$name)
  
  # Copy vertex attributes
  for(attr in igraph::list.vertex.attributes(g_voting)) {
    if(attr != "name") {
      igraph::vertex_attr(g_with_attr, attr) <- igraph::vertex_attr(g_voting, attr)
    }
  }
  
  return(g_with_attr)
}

# Filter co-sponsorship and coalition edgelists to match study 2 parties (all parties)
edgelist_cosponsor_pre_filtered <- edgelist_cosponsor_pre[
  edgelist_cosponsor_pre$from %in% all_parties_study2 & 
  edgelist_cosponsor_pre$to %in% all_parties_study2, 
]

edgelist_cosponsor_post_filtered <- edgelist_cosponsor_post[
  edgelist_cosponsor_post$from %in% all_parties_study2 & 
  edgelist_cosponsor_post$to %in% all_parties_study2, 
]

coalition_edgelist_pre_filtered <- coalition_edgelist_filtered[
  coalition_edgelist_filtered$from %in% all_parties_study2 & 
  coalition_edgelist_filtered$to %in% all_parties_study2, 
]

coalition_edgelist_post_filtered <- coalition_edgelist_filtered[
  coalition_edgelist_filtered$from %in% all_parties_study2 & 
  coalition_edgelist_filtered$to %in% all_parties_study2, 
]

# Add edge attributes
g_study2_pre <- add_edge_attribute(g_study2_pre, edgelist_cosponsor_pre_filtered, "cosponsor_count")
g_study2_pre <- add_edge_attribute(g_study2_pre, coalition_edgelist_pre_filtered, "coalition_count")

g_study2_post <- add_edge_attribute(g_study2_post, edgelist_cosponsor_post_filtered, "cosponsor_count")
g_study2_post <- add_edge_attribute(g_study2_post, coalition_edgelist_post_filtered, "coalition_count")

print("STUDY 2: EDGE ATTRIBUTES ADDED")
print("===============================")
print("Co-sponsorship and coalition counts added as edge attributes")
print("Networks are already fully connected from general preprocessing")
print("Networks ready for GERGM analysis")
```

------------------------------------------------------------------------

# 5. QAP Analysis (Study 1)

## 5.1 Overview

QAP (Quadratic Assignment Procedure) is used in Study 1 to test whether the network structure changed significantly between the pre-election and post-formation periods. QAP compares two networks by:

1. Computing a test statistic (e.g., correlation) between the two adjacency matrices
2. Permuting rows and columns of one matrix to generate a null distribution
3. Comparing the observed statistic to the null distribution to assess significance

## 5.2 Prepare Data for QAP

```{r qap-prepare}
# Load required packages
if(!require(sna)) install.packages("sna")
library(sna)

# Create results directory if it doesn't exist
if(!dir.exists("results/statistics")) {
  dir.create("results/statistics", recursive = TRUE)
}

# Ensure matrices are properly aligned (same row/column order)
# Both matrices should already have the same party order from Study 1 preprocessing
party_order <- rownames(adj_matrix_pre)

# Verify alignment
if(!all(rownames(adj_matrix_pre) == rownames(adj_matrix_post)) ||
   !all(colnames(adj_matrix_pre) == colnames(adj_matrix_post))) {
  stop("Adjacency matrices are not aligned!")
}

print("QAP DATA PREPARATION")
print("====================")
print(sprintf("Pre-election matrix: %d x %d", nrow(adj_matrix_pre), ncol(adj_matrix_pre)))
print(sprintf("Post-formation matrix: %d x %d", nrow(adj_matrix_post), ncol(adj_matrix_post)))
print(sprintf("Number of parties: %d", length(party_order)))
print("Matrices are aligned and ready for QAP analysis")
```

## 5.3 Network-Level Metrics Comparison

```{r qap-metrics}
# Calculate network-level metrics for comparison
# Using snafun for basic metrics and base R/igraph for others

# Pre-election metrics
g_pre <- g_study1_pre_connected
g_post <- g_study1_post_connected

metrics_pre <- list(
  vertices = snafun::count_vertices(g_pre),
  edges = snafun::count_edges(g_pre),
  density = snafun::g_density(g_pre),
  mean_degree = mean(igraph::degree(g_pre)),
  mean_weight = mean(igraph::E(g_pre)$weight),
  max_weight = max(igraph::E(g_pre)$weight),
  min_weight = min(igraph::E(g_pre)$weight)
)

metrics_post <- list(
  vertices = snafun::count_vertices(g_post),
  edges = snafun::count_edges(g_post),
  density = snafun::g_density(g_post),
  mean_degree = mean(igraph::degree(g_post)),
  mean_weight = mean(igraph::E(g_post)$weight),
  max_weight = max(igraph::E(g_post)$weight),
  min_weight = min(igraph::E(g_post)$weight)
)

# Create comparison table
metrics_comparison <- data.frame(
  Metric = c("Vertices", "Edges", "Density", "Mean Degree", 
             "Mean Weight", "Max Weight", "Min Weight"),
  Pre_Election = c(
    metrics_pre$vertices,
    metrics_pre$edges,
    sprintf("%.4f", metrics_pre$density),
    sprintf("%.2f", metrics_pre$mean_degree),
    sprintf("%.4f", metrics_pre$mean_weight),
    sprintf("%.4f", metrics_pre$max_weight),
    sprintf("%.4f", metrics_pre$min_weight)
  ),
  Post_Formation = c(
    metrics_post$vertices,
    metrics_post$edges,
    sprintf("%.4f", metrics_post$density),
    sprintf("%.2f", metrics_post$mean_degree),
    sprintf("%.4f", metrics_post$mean_weight),
    sprintf("%.4f", metrics_post$max_weight),
    sprintf("%.4f", metrics_post$min_weight)
  ),
  stringsAsFactors = FALSE
)

print("NETWORK-LEVEL METRICS COMPARISON")
print("=================================")
print(metrics_comparison)
```

## 5.4 QAP Correlation Test

```{r qap-correlation}
# Perform QAP correlation test using matrices directly
# This tests whether the correlation between the two networks is significant
# H1.1: Dutch political parties show different levels of voting agreement 
#       before elections compared to after cabinet formation
# Note: Warnings about "standard deviation is zero" during permutations are 
#       typically harmless and occur when some permuted rows/columns are constant
set.seed(12345)

# Compute observed correlation
observed_corr <- sna::gcor(adj_matrix_pre, adj_matrix_post)
print(sprintf("Observed correlation: %.4f", observed_corr))

# Perform QAP test using matrices directly (sna::gcor works with matrices)
suppressWarnings({
  qap_result <- sna::qaptest(
    list(adj_matrix_pre, adj_matrix_post),
    FUN = sna::gcor,
    reps = 1000,
    g1 = 1,
    g2 = 2
  )
})

print("QAP CORRELATION TEST")
print("====================")
print(sprintf("Observed correlation: %.4f", qap_result$testval))
print(sprintf("Number of permutations: %d", qap_result$reps))
print("")
print("QAP Test Summary:")
print(summary(qap_result))
```

## 5.5 QAP Results Interpretation

```{r qap-interpretation}
# Extract p-value and interpret results
p_value <- mean(qap_result$dist >= qap_result$testval)

print("QAP RESULTS INTERPRETATION")
print("===========================")
print(sprintf("Observed correlation: %.4f", qap_result$testval))
print(sprintf("P-value (one-tailed): %.4f", p_value))
print(sprintf("P-value (two-tailed): %.4f", 2 * min(p_value, 1 - p_value)))
print("")
if(p_value < 0.05) {
  print("Interpretation: The correlation between pre-election and post-formation")
  print("networks is statistically significant (p < 0.05).")
  print("The network structures are significantly similar.")
} else {
  print("Interpretation: The correlation between pre-election and post-formation")
  print("networks is NOT statistically significant (p >= 0.05).")
  print("The network structures differ significantly between periods.")
}

# Save QAP results
qap_summary <- list(
  observed_correlation = qap_result$testval,
  p_value_one_tailed = p_value,
  p_value_two_tailed = 2 * min(p_value, 1 - p_value),
  n_permutations = qap_result$reps,
  interpretation = ifelse(p_value < 0.05, 
                         "Networks are significantly similar",
                         "Networks differ significantly")
)

# Export results
save(qap_result, qap_summary, metrics_comparison,
     file = "results/statistics/qap_results.RData")
print("")
print("QAP results saved to results/statistics/qap_results.RData")
```

------------------------------------------------------------------------

# 6. GERGM Setup

## 6.1 Overview

GERGM (Generalized Exponential Random Graph Model) will be used in Study 2 to model network formation with covariates. GERGM allows us to test hypotheses about which factors influence voting agreement between parties.

## 6.2 Hypotheses and Model Terms

The GERGM will test the following hypotheses:

-   **H2.1**: Parties with similar ideologies on the left-right spectrum are more likely to agree on motions.
    -   *Term*: `absdiff(LeftVSRight)` - measures how differences in ideology impact tie formation
-   **H2.2**: Parties that have often been in a coalition together are more likely to agree on motions.
    -   *Term*: `edgecov(coalitioncount)` - uses coalition count as edge covariate
-   **H2.3**: Parties are more likely to agree on motions if they share agreement on motions with a third party.
    -   *Term*: `gwesp` - captures transitivity/triadic closure
-   **H2.4**: Some parties are more likely to agree with many other parties.
    -   *Term*: `kstar(3)` - captures tendency for some parties to form broader cooperation patterns
-   **H2.5**: Parties who frequently co-sponsor motions tend to agree more with each other.
    -   *Term*: `edgecov(cosponsor_count)` - uses co-sponsorship count as edge covariate

## Pre election network 

```{r}

#### 6.3 Pre-election GERGM specification and estimation ----
# Assumes:
# - g_study2_pre already HAS edge attributes: weight, cosponsor_count, coalition_count
# - node attribute: left_right
# - edge covariate edgelists already added earlier in the pipeline
# - libraries GERGM and igraph loaded



## 1. Valued adjacency matrix (voting agreement, z-score normalized) ----------
net_pre <- igraph::as_adjacency_matrix(
  g_study2_pre,
  attr   = "weight",   # weight_normalized
  sparse = FALSE
)

party_names_pre <- igraph::V(g_study2_pre)$name
rownames(net_pre) <- party_names_pre
colnames(net_pre) <- party_names_pre
diag(net_pre)     <- 0

## 2. Node-level covariates (left–right ideology) -----------------------------
left_right_pre <- igraph::V(g_study2_pre)$left_right

node_covariates_pre <- data.frame(
  left_right = left_right_pre,
  row.names  = party_names_pre,
  stringsAsFactors = FALSE
)

## 3. Edge-level covariates as matrices (co-sponsorship, coalition) ----------
cosponsor_mat_pre <- igraph::as_adjacency_matrix(
  g_study2_pre,
  attr   = "cosponsor_count",
  sparse = FALSE
)

coalition_mat_pre <- igraph::as_adjacency_matrix(
  g_study2_pre,
  attr   = "coalition_count",
  sparse = FALSE
)

rownames(cosponsor_mat_pre) <- party_names_pre
colnames(cosponsor_mat_pre) <- party_names_pre

rownames(coalition_mat_pre) <- party_names_pre
colnames(coalition_mat_pre) <- party_names_pre

diag(cosponsor_mat_pre)  <- 0
diag(coalition_mat_pre)  <- 0

## 4. GERGM formula: pre-election network -------------------------------------
formula_pre <- net_pre ~
  edges(method = "endogenous") +
  twostars(alpha = 0.8) +
  ttriads(alpha = 0.8) +
  absdiff("left_right") +
  netcov("cosponsor_mat_pre") +
  netcov("coalition_mat_pre")

## 5. Estimate pre-election GERGM ---------------------------------------------
set.seed(1234)

gergm_pre <- GERGM::gergm(
  formula                        = formula_pre,
  covariate_data                 = node_covariates_pre,
  network_is_directed            = FALSE,
  include_diagonal               = FALSE,
  normalization_type             = "division",
  distribution_estimator         = "none",
  number_of_networks_to_simulate = 50000,
  MCMC_burnin                    = 20000,
  thin                           = 1 / 10,
  proposal_variance              = 0.2,
  target_accept_rate             = 0.25,
  seed                           = 1234,
  convergence_tolerance          = 0.01,
  force_x_theta_updates          = 5,
  sample_edges_at_a_time         = 0
)

## 6. Output -------------------------------------------------------------------
summary(gergm_pre)

# Optional diagnostics:
# GERGM::Estimate_Plot(gergm_pre)
# GERGM::GOF(gergm_pre)
# GERGM::Trace_Plot(gergm_pre)

# Optional save:
# saveRDS(gergm_pre, file = "results/models/gergm_pre_election.rds")
```

## Post election network

```{r}

net_post <- igraph::as_adjacency_matrix(
  g_study2_post,
  attr   = "weight",   # weight_normalized
  sparse = FALSE
)

party_names_post <- igraph::V(g_study2_post)$name
rownames(net_post) <- party_names_post
colnames(net_post) <- party_names_post
diag(net_post)     <- 0

## 2. Node-level covariates (left–right ideology) -----------------------------
left_right_post <- igraph::V(g_study2_post)$left_right

node_covariates_post <- data.frame(
  left_right = left_right_post,
  row.names  = party_names_post,
  stringsAsFactors = FALSE
)

## 3. Edge-level covariates as matrices (co-sponsorship, coalition) ----------
cosponsor_mat_post <- igraph::as_adjacency_matrix(
  g_study2_post,
  attr   = "cosponsor_count",
  sparse = FALSE
)

coalition_mat_post <- igraph::as_adjacency_matrix(
  g_study2_post,
  attr   = "coalition_count",
  sparse = FALSE
)

rownames(cosponsor_mat_post) <- party_names_post
colnames(cosponsor_mat_post) <- party_names_post

rownames(coalition_mat_post) <- party_names_post
colnames(coalition_mat_post) <- party_names_post

diag(cosponsor_mat_post)  <- 0
diag(coalition_mat_post)  <- 0

## 4. GERGM formula: post-formation network -----------------------------------
formula_post <- net_post ~
  edges(method = "endogenous") +
  twostars(alpha = 0.8) +
  ttriads(alpha = 0.8) +
  absdiff("left_right") +
  netcov("cosponsor_mat_post") +
  netcov("coalition_mat_post")

## 5. Estimate post-formation GERGM -------------------------------------------
set.seed(1234)

gergm_post <- GERGM::gergm(
  formula                        = formula_post,
  covariate_data                 = node_covariates_post,
  network_is_directed            = FALSE,
  include_diagonal               = FALSE,
  normalization_type             = "division",
  distribution_estimator         = "none",
  number_of_networks_to_simulate = 50000,
  MCMC_burnin                    = 20000,
  thin                           = 1 / 10,
  proposal_variance              = 0.2,
  target_accept_rate             = 0.25,
  seed                           = 1234,
  convergence_tolerance          = 0.01,
  force_x_theta_updates          = 5,
  sample_edges_at_a_time         = 0
)

## 6. Output -------------------------------------------------------------------
summary(gergm_post)

# Optional diagnostics:
# GERGM::Estimate_Plot(gergm_post)
# GERGM::GOF(gergm_post)
# GERGM::Trace_Plot(gergm_post)

# Optional save:
# saveRDS(gergm_post, file = "results/models/gergm_post_formation.rds")
```

# 7. Summary

## 7.1 Preprocessing Summary

```{r summary}
print("PREPROCESSING SUMMARY")
print("====================")
print("")
print("DATA PREPARATION:")
print(sprintf("  • Pre-election: %s votes, %s motions, %d parties", 
              format(nrow(motion_data_pre), big.mark = ","),
              format(length(unique(motion_data_pre$Besluit_Id)), big.mark = ","),
              length(unique(motion_data_pre$ActorFractie))))
print(sprintf("  • Post-formation: %s votes, %s motions, %d parties", 
              format(nrow(motion_data_post), big.mark = ","),
              format(length(unique(motion_data_post$Besluit_Id)), big.mark = ","),
              length(unique(motion_data_post$ActorFractie))))
print("")
print("FULLY CONNECTED NETWORKS (GENERAL PREPROCESSING):")
print(sprintf("  • Pre-election: %d nodes, fully connected (%d edges)", 
              snafun::count_vertices(g_pre_connected), snafun::count_edges(g_pre_connected)))
print(sprintf("  • Post-formation: %d nodes, fully connected (%d edges)", 
              snafun::count_vertices(g_post_connected), snafun::count_edges(g_post_connected)))
print("  • All zero edge weights set to 1e-6 for full connectivity")
print("  • Adjacency matrices exported")
print("")
print("STUDY 1 (QAP):")
print("  • Uses fully connected networks from general preprocessing")
print("  • Ready for QAP correlation test")
print("")
print("STUDY 2 (GERGM):")
print(sprintf("  • Pre-election: %d nodes, fully connected (%d edges)", 
              snafun::count_vertices(g_study2_pre), snafun::count_edges(g_study2_pre)))
print(sprintf("  • Post-formation: %d nodes, fully connected (%d edges)", 
              snafun::count_vertices(g_study2_post), snafun::count_edges(g_study2_post)))
print("  • Same node set for comparability between periods")
print("  • Ideology, co-sponsorship, and coalition attributes added")
print("  • Ready for GERGM analysis")
```

## 7.2 Files Generated

All preprocessing outputs have been saved to:

-   **Adjacency Matrices:** `results/adjacency_matrices/`
    -   `pre_election_adjacency.csv`
    -   `post_formation_adjacency.csv`
-   **Statistics:** `results/statistics/`
-   **Visualizations:** `results/visualizations/`

------------------------------------------------------------------------

# Session Info

```{r session-info}
sessionInfo()
```
